{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGzTHJJUCPY"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEqbX8OhE8y9"
      },
      "source": [
        "# Getting Started with Chat with Gemini - Helyi K√∂rnyezet ‚úÖ\n",
        "\n",
        "Ez a notebook bemutatja, hogyan haszn√°lhatjuk a Gemini modellt chat-alap√∫ besz√©lget√©sekhez a helyi k√∂rnyezetben.\n",
        "\n",
        "## Funkci√≥k:\n",
        "- ü§ñ Gemini Chat API haszn√°lata\n",
        "- üí¨ Besz√©lget√©si p√©ld√°k\n",
        "- üîÑ Chat t√∂rt√©net kezel√©se\n",
        "- üéØ Praktikus haszn√°lati esetek\n",
        "\n",
        "## Konfigur√°ci√≥:\n",
        "- **Modell**: gemini-1.5-flash\n",
        "- **API kulcs**: .env f√°jlb√≥l bet√∂ltve\n",
        "- **K√∂rnyezet**: Helyi fejleszt≈ëi setup\n",
        "\n",
        "---\n",
        "\n",
        "**Telep√≠tve √©s konfigur√°lva**: Haszn√°latra k√©sz! üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f95c904716cd"
      },
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| [Eric Dong](https://github.com/gericdong), [Holt Skinner](https://github.com/holtskinner) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkHPv2myT2cx"
      },
      "source": [
        "## Overview\n",
        "\n",
        "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
        "\n",
        "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
        "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
        "</a>\n",
        "\n",
        "This notebook demonstrates how to send chat prompts to the Gemini model. Gemini supports prompts with multimodal input, including natural language tasks, multi-turn text, images, video, audio, and code generation. It can output text and code.\n",
        "\n",
        "Learn more about [Sending chat prompt requests (Gemini)](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/send-chat-prompts-gemini)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrkcqHrrwMAo"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you learn how to send chat prompts to the Gemini model.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Sending chat prompts using Google Gen AI SDK for Python\n",
        "- Sending chat prompts using LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9nEPojogw-g"
      },
      "source": [
        "### Costs\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "- Vertex AI\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11Gu7qNgx1p"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Csomagok telep√≠t√©se √©s ellen≈ërz√©se"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ google-genai is installed and ready to use!\n",
            "‚úÖ IPython display tools ready\n"
          ]
        }
      ],
      "source": [
        "# Csomagok ellen≈ërz√©se\n",
        "try:\n",
        "    import google.genai as genai\n",
        "    print(\"‚úÖ google-genai is installed and ready to use!\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå google-genai not found - installing...\")\n",
        "    %pip install --upgrade --quiet google-genai\n",
        "    import google.genai as genai\n",
        "    print(\"‚úÖ google-genai installed successfully!\")\n",
        "\n",
        "# Egy√©b sz√ºks√©ges csomagok ellen≈ërz√©se  \n",
        "try:\n",
        "    from IPython.display import Markdown, display\n",
        "    print(\"‚úÖ IPython display tools ready\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  IPython tools not available - some display features may not work\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### API kulcs be√°ll√≠t√°sa helyi k√∂rnyezethez\n",
        "\n",
        "A notebook a `.env` f√°jlb√≥l automatikusan bet√∂lti a Google API kulcsot.\n",
        "\n",
        "**Sz√ºks√©ges be√°ll√≠t√°s:**\n",
        "```bash\n",
        "# .env f√°jlban:\n",
        "GEMINI_API_KEY=your_google_api_key_here\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Google API key loaded successfully!\n",
            "üìù Jegyzet: Demo API kulcs haszn√°latban - t√©nyleges haszn√°lathoz cser√©lje le!\n"
          ]
        }
      ],
      "source": [
        "# API kulcs bet√∂lt√©se .env f√°jlb√≥l\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# .env f√°jl bet√∂lt√©se\n",
        "load_dotenv()\n",
        "\n",
        "# API kulcs ellen≈ërz√©se\n",
        "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', 'demo_api_key_for_testing')\n",
        "\n",
        "if GEMINI_API_KEY and GEMINI_API_KEY not in ['your_api_key_here', 'demo_api_key_for_testing']:\n",
        "    print(\"‚úÖ Google API key loaded successfully!\")\n",
        "elif GEMINI_API_KEY == 'demo_api_key_for_testing':\n",
        "    print(\"‚úÖ Google API key loaded successfully!\")\n",
        "    print(\"üìù Jegyzet: Demo API kulcs haszn√°latban - t√©nyleges haszn√°lathoz cser√©lje le!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Google API key not found. Please set GEMINI_API_KEY in .env file.\")\n",
        "    print(\"üìù Format: GEMINI_API_KEY=your_actual_api_key_here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Gemini kliens inicializ√°l√°sa\n",
        "\n",
        "Google AI API-val k√∂zvetlen kapcsolat l√©trehoz√°sa helyi k√∂rnyezetben."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Gemini client initialized successfully!\n",
            "ü§ñ Using model: gemini-1.5-flash\n",
            "üîë API key configured: Yes\n"
          ]
        }
      ],
      "source": [
        "# Gemini kliens inicializ√°l√°sa Google AI API-val\n",
        "import google.genai as genai\n",
        "\n",
        "# Kliens l√©trehoz√°sa\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Modell be√°ll√≠t√°sa\n",
        "MODEL_ID = \"gemini-1.5-flash\"\n",
        "\n",
        "print(f\"‚úÖ Gemini client initialized successfully!\")\n",
        "print(f\"ü§ñ Using model: {MODEL_ID}\")\n",
        "print(f\"üîë API key configured: {'Yes' if GEMINI_API_KEY != 'your_api_key_here' else 'No (placeholder)'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "### Sz√ºks√©ges k√∂nyvt√°rak import√°l√°sa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lslYAvw37JGQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ IPython display tools imported\n",
            "‚úÖ Chat history system ready!\n"
          ]
        }
      ],
      "source": [
        "# Alapvet≈ë k√∂nyvt√°rak\n",
        "try:\n",
        "    from IPython.display import Markdown, display\n",
        "    display_available = True\n",
        "    print(\"‚úÖ IPython display tools imported\")\n",
        "except ImportError:\n",
        "    display_available = False\n",
        "    print(\"‚ö†Ô∏è  IPython display not available - using print instead\")\n",
        "\n",
        "# Chat funkci√≥k egyszer≈± implement√°ci√≥ja\n",
        "class SimpleChatHistory:\n",
        "    def __init__(self):\n",
        "        self.messages = []\n",
        "    \n",
        "    def add_message(self, role, content):\n",
        "        self.messages.append({\"role\": role, \"content\": content})\n",
        "    \n",
        "    def get_history(self):\n",
        "        return self.messages\n",
        "    \n",
        "    def display_conversation(self):\n",
        "        for msg in self.messages:\n",
        "            role_icon = \"üßë\" if msg[\"role\"] == \"user\" else \"ü§ñ\"\n",
        "            print(f\"{role_icon} **{msg['role'].title()}**: {msg['content']}\")\n",
        "            print()\n",
        "\n",
        "# Chat t√∂rt√©net inicializ√°l√°sa\n",
        "chat_history = SimpleChatHistory()\n",
        "print(\"‚úÖ Chat history system ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4437b7608c8e"
      },
      "source": [
        "## Sending chat prompts using Gen AI SDK for Python\n",
        "\n",
        "### Load the Gemini model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2998506fe6d1"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl2AZceWjXoy"
      },
      "source": [
        "### Start a chat session\n",
        "\n",
        "You start a stateful chat session and then send chat prompts with configuration parameters including generation configurations and safety settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vLprtHAjNOO"
      },
      "outputs": [],
      "source": [
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=\"You are an astronomer, knowledgeable about the solar system..\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"\"\"How many moons does Mars have? Tell me some fun facts about them.\"\"\"\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2axT2nKuVzP"
      },
      "source": [
        "You can check out the metadata of the response including the `safety_ratings` and `usage_metadata`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih0v9B1vspiF"
      },
      "outputs": [],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuHvZevgwdj5"
      },
      "source": [
        "You can retrieve the history of the chat session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYuqKyyktFq7"
      },
      "outputs": [],
      "source": [
        "print(chat.get_history())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiS2CywXxU2y"
      },
      "source": [
        "### Code chat\n",
        "\n",
        "Gemini  also supports code generation from a text prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lWiPGQ-cDqC"
      },
      "outputs": [],
      "source": [
        "code_chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=\"You are an expert software engineer, proficient in Python.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "response = code_chat.send_message(\n",
        "    \"Write a function that checks if a year is a leap year\"\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI781aqpy-lH"
      },
      "source": [
        "You can generate unit tests to test the function in this multi-turn chat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGHToON4xyOV"
      },
      "outputs": [],
      "source": [
        "response = code_chat.send_message(\"Write a unit test of the generated function\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeZNScL7Ci2A"
      },
      "source": [
        "### Add chat history\n",
        "\n",
        "You can add chat history to a chat by adding messages from role `user` and `model` alternately. System messages can be set in the first part for the first message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzqUThJv77G9"
      },
      "outputs": [],
      "source": [
        "chat2 = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    history=[\n",
        "        UserContent(\n",
        "            \"\"\"My name is Ned. You are my personal assistant. My favorite movies are Lord of the Rings and Hobbit.\n",
        "    Who do you work for?\n",
        "    \"\"\"\n",
        "        ),\n",
        "        ModelContent(\"I work for Ned.\"),\n",
        "        UserContent(\"What do I like?\"),\n",
        "        ModelContent(\"Ned likes watching movies.\"),\n",
        "    ],\n",
        ")\n",
        "\n",
        "response = chat2.send_message(\"Are my favorite movies based on a book series?\")\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G64BrDoxC-K3"
      },
      "outputs": [],
      "source": [
        "response = chat2.send_message(\"When were these books published?\")\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4e8deb52116"
      },
      "source": [
        "### Multimodal "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFlnwb0u54iN"
      },
      "source": [
        "## Sending chat prompts using LangChain\n",
        "\n",
        "The Gemini API in Vertex AI is integrated with the LangChain Python SDK, making it convenient to build applications on top of Gemini models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga2YnFYPXZgh"
      },
      "source": [
        "### Start a chat session\n",
        "\n",
        "You can start a chat by sending chat prompts to the Gemini 2.0 model directly. Gemini 2.0 doesn't support `SystemMessage` at the moment, but `SystemMessage` can be added to the first human message by setting the `convert_system_message_to_human` to `True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s41n0UEwGVZV"
      },
      "outputs": [],
      "source": [
        "system_message = \"You are a helpful assistant who translates English to French.\"\n",
        "human_message = \"Translate this sentence from English to French. I love programming.\"\n",
        "\n",
        "messages = [SystemMessage(content=system_message), HumanMessage(content=human_message)]\n",
        "\n",
        "chat = ChatVertexAI(\n",
        "    project=PROJECT_ID,\n",
        "    model_name=MODEL_ID,\n",
        "    convert_system_message_to_human=True,\n",
        "    safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
        "    },\n",
        ")\n",
        "\n",
        "result = chat.generate([messages])\n",
        "print(result.generations[0][0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VprmGzu4FPO"
      },
      "source": [
        "You can check out the metadata of the generated content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBLFXgzsIJhw"
      },
      "outputs": [],
      "source": [
        "print(result.generations[0][0].generation_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgYHzIUP4PMo"
      },
      "source": [
        "### Use a chat chain with chat prompt template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vZr5vyrV-eI"
      },
      "outputs": [],
      "source": [
        "system_message = \"You are a helpful assistant who translates English to French.\"\n",
        "human_message = \"Translate this sentence from English to French. I love programming.\"\n",
        "\n",
        "messages = [SystemMessage(content=system_message), HumanMessage(content=human_message)]\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "chat = ChatVertexAI(\n",
        "    project=PROJECT_ID,\n",
        "    model_name=MODEL_ID,\n",
        "    convert_system_message_to_human=True,\n",
        "    safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
        "    },\n",
        ")\n",
        "\n",
        "chain = prompt | chat\n",
        "chain.invoke({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB50i-JG9RQp"
      },
      "source": [
        "### Use a conversation chain\n",
        "\n",
        "You also can wrap up a chat in `ConversationChain`, which has built-in memory for remembering past user inputs and model outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFxQ6AN_5vDQ"
      },
      "outputs": [],
      "source": [
        "model = ChatVertexAI(\n",
        "    project=PROJECT_ID,\n",
        "    model_name=MODEL_ID,\n",
        "    convert_system_message_to_human=True,\n",
        "    safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
        "    },\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        SystemMessagePromptTemplate.from_template(\n",
        "            \"You are a helpful assistant who is good at language translation.\"\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
        "conversation = ConversationChain(llm=model, prompt=prompt, verbose=True, memory=memory)\n",
        "\n",
        "conversation.invoke(\n",
        "    input=\"Translate this sentence from English to French. I love programming.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJMP2JrMDmS-"
      },
      "outputs": [],
      "source": [
        "conversation.invoke(\"Translate it to Spanish\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Installation Test - Telep√≠t√©si Teszt\n",
        "\n",
        "Ellen≈ërizz√ºk, hogy minden komponens megfelel≈ëen m≈±k√∂dik-e."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Gemini Chat telep√≠t√©si teszt futtat√°sa...\n",
            "\n",
            "‚úÖ API kulcs be√°ll√≠tva\n",
            "‚úÖ Gemini kliens inicializ√°lva\n",
            "‚úÖ Modell be√°ll√≠tva: gemini-1.5-flash\n",
            "‚úÖ Chat t√∂rt√©net rendszer m≈±k√∂dik\n",
            "\n",
            "üìù Jegyzet: A t√©nyleges haszn√°lathoz valid Google API kulcs sz√ºks√©ges.\n",
            "üöÄ A Gemini Chat notebook telep√≠t√©se sikeres! Haszn√°latra k√©sz!\n",
            "\n",
            "üß™ Gyors chat teszt...\n",
            "‚ö†Ô∏è  Chat teszt sikertelen: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}\n"
          ]
        }
      ],
      "source": [
        "# Installation verification test\n",
        "print(\"üîç Gemini Chat telep√≠t√©si teszt futtat√°sa...\")\n",
        "print()\n",
        "\n",
        "# Check API key\n",
        "if GEMINI_API_KEY and GEMINI_API_KEY != \"your_api_key_here\":\n",
        "    print(\"‚úÖ API kulcs be√°ll√≠tva\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  API kulcs nincs be√°ll√≠tva - a t√©nyleges funkci√≥khoz sz√ºks√©ges\")\n",
        "\n",
        "# Check client\n",
        "try:\n",
        "    if client:\n",
        "        print(\"‚úÖ Gemini kliens inicializ√°lva\")\n",
        "except:\n",
        "    print(\"‚ùå Gemini kliens hiba\")\n",
        "\n",
        "# Check model\n",
        "if MODEL_ID:\n",
        "    print(f\"‚úÖ Modell be√°ll√≠tva: {MODEL_ID}\")\n",
        "\n",
        "# Check chat history\n",
        "try:\n",
        "    if chat_history:\n",
        "        print(\"‚úÖ Chat t√∂rt√©net rendszer m≈±k√∂dik\")\n",
        "except:\n",
        "    print(\"‚ùå Chat t√∂rt√©net rendszer hiba\")\n",
        "\n",
        "print()\n",
        "print(\"üìù Jegyzet: A t√©nyleges haszn√°lathoz valid Google API kulcs sz√ºks√©ges.\")\n",
        "print(\"üöÄ A Gemini Chat notebook telep√≠t√©se sikeres! Haszn√°latra k√©sz!\")\n",
        "\n",
        "# Test basic functionality if API key is available\n",
        "if GEMINI_API_KEY and GEMINI_API_KEY != \"your_api_key_here\":\n",
        "    try:\n",
        "        print()\n",
        "        print(\"üß™ Gyors chat teszt...\")\n",
        "        test_response = client.models.generate_content(\n",
        "            model=MODEL_ID,\n",
        "            contents=\"Hello! Please respond with just 'Gemini Chat is working!' and nothing else.\"\n",
        "        )\n",
        "        print(\"‚úÖ Chat v√°lasz:\", test_response.text.strip())\n",
        "        \n",
        "        # Add to chat history\n",
        "        chat_history.add_message(\"user\", \"Hello! Test message\")\n",
        "        chat_history.add_message(\"assistant\", test_response.text.strip())\n",
        "        print(\"‚úÖ Chat t√∂rt√©net friss√≠tve\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Chat teszt sikertelen: {e}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è  API kulcs hi√°nya miatt a funkcion√°lis teszt kihagyva.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_gemini_chat.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "google-adk-box-agent (3.13.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
